---
tags:
  - Loss
  - Contrastive
todo: false
summary: A improved loss for contrastive learning.
---
# Summary
💡 Write a brief summary of this paper here
Improved [[NCE]] using all the data and all the classes.
This can be seen as [[Cross Entropy]] between data pairs (Multiclass classification).

![[Pasted image 20240409123158.png]]
# Resources
💡 Include some useful links or related papers for better understanding of this concept
- [Original Paper: Representation Learning with Contrastive Predictive Coding](https://arxiv.org/pdf/1807.03748v2.pdf)
![[Pasted image 20240528171720.png]]
- [對比學習介紹](https://u9534056.medium.com/%E9%9D%A2%E8%A9%A6%E5%BF%85%E5%82%99-%E5%B0%8D%E6%AF%94%E5%AD%B8%E7%BF%92-contrastive-learning-%E4%B8%BB%E6%B5%81%E6%96%B9%E6%B3%95%E4%B8%80%E8%A6%BD-bddf2afc5e5f)
- [InfoNCE Loss 損失函數](https://blog.csdn.net/qq_46006468/article/details/126076039)
- [比較學習損失（InfoNCE loss）與交叉熵損失的聯繫，以及溫度係數的作用](https://zhuanlan.zhihu.com/p/506544456)
- [PWC](https://paperswithcode.com/method/infonce)
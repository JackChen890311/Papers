---
title: "ConceptLab: Creative Concept Generation using VLM-Guided Diffusion Prior Constraints"
time: 2308
author: Tel Aviv University
link: https://arxiv.org/pdf/2308.02669
accepted: ACM24
tags:
  - Contrastive
  - Diffusion
  - Generation
  - Multimodal
  - LLM
  - Text
  - Image
todo: false
scanned: true
read: false
summary: " A contrastive based method for creative concept generation, with the help of VLM and diffusion prior."
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
![[Pasted image 20240501164223.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20240501164240.png]]
- A Diffusion Prior model, introduced in [[unCLIP]], is tasked with mapping an input text embedding to its corresponding image embedding in [[CLIP]]'s latent space.
- The new concept token is similar to [[Textual Inversion]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper
![[Pasted image 20240501164312.png]]
# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
---
title: "Constitutional AI: Harmlessness from AI Feedback"
time: 2212
author: Anthropic
link: https://arxiv.org/pdf/2212.08073.pdf
accepted: None
tags:
  - LLM
  - Text
todo: false
scanned: true
read: false
summary:
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
Use [[LLM]] (AI) to do reinforcement learning -> RLAIF (Reinforcement Learning from AI Feedback). 
With guildline (constitution) provided by human, we can save the annotation time using traditional RLHF (Reinforcement Learning from Human Feedback). 
This paper is used by Anthorpic to build Claude.
![[Pasted image 20240414171124.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper

# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
![[Pasted image 20240427153401.png]]
# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
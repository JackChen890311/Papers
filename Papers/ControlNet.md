---
title: Adding Conditional Control to Text-to-Image Diffusion Models
time: 2302
author: Stanford University
link: https://arxiv.org/pdf/2302.05543.pdf
accepted: ICCV23
tags:
  - Image
  - Multimodal
  - Generation
  - Diffusion
  - Add-on
todo: false
scanned: true
read: true
summary: Proposed a plugged-in control module that enables diffusion model to follow the conditions from different modalities.
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
![[Pasted image 20240116202310.png]]
![[Pasted image 20240116202324.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20240116202432.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one
- Previous Work: [[DreamBooth]]
# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not metioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
- [ControlNet](https://docs.google.com/presentation/d/15HjdDtalaJr0lAT6ir4p9ejSJQpS9UHIbZvgz7BktFc/edit#slide=id.p)

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
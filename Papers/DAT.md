---
title: Vision Transformer with Deformable Attention
time: 2201
author: Tsinghua University; AWS AI, Amazon; Beijing Academy of Artificial Intelligence
link: https://arxiv.org/pdf/2201.00520
accepted: CVPR22
tags:
  - Add-on
  - Foundation
  - Image
todo: true
scanned: false
read: false
summary:
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
![[Pasted image 20251015184053.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20251015184108.png]]
![[Pasted image 20251017165906.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one
- [[Deformable DETR]]
- [[ViT]]
- [[Swin Transformer]]
- [[DCN]]
![[Pasted image 20251017162547.png]]
# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
- [è«–æ–‡ç­†è¨˜ â€” Vision Transformer with Deformable Attention](https://watson-john.medium.com/%E8%AB%96%E6%96%87%E7%AD%86%E8%A8%98-vision-transformer-with-deformable-attention-6e94fa8d0af9)
# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
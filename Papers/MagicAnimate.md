---
title: "MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model"
time: 2311
author: Show Lab, National University of Singapore; ByteDance
link: https://arxiv.org/pdf/2311.16498.pdf
accepted: None
tags:
  - Image
  - Video
  - Multimodal
  - HumanPose
  - Generation
  - Diffusion
todo: false
scanned: true
read: true
summary: A human animation model, based on stable diffusion, control net and temporal layer, conditioned on reference image and densepose motion sequence.
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
![[Pasted image 20240116180403.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper

# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one
Use [[LDM]] as base model, adapt the idea of motion block from [[AnimateDiff]].
Use [[ControlNet]] to take pose/depth as guidance.
# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
- [Project Page](https://showlab.github.io/magicanimate/)
- [Human Animation](https://docs.google.com/presentation/d/17OTLGDjjYoZJA6TdNU4ecOPky7Xja3MViUpTYSfNXjM/edit#slide=id.g2a7f2eb90a5_0_61)

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
---
title: Null-text Inversion for Editing Real Images using Guided Diffusion Models
time: 2211
author: Google Research; The Blavatnik School of Computer Science; Tel Aviv University
link: https://arxiv.org/pdf/2211.09794
accepted: CVPR23
tags:
  - Diffusion
  - Generation
  - Image
  - Text
  - Multimodal
  - Personalization
todo: true
scanned: false
read: false
summary: A method to inverse the DDIM process with CFG added, thus makes image editting possible and with good fidelity .
---
# Summary
ğŸ’¡ Write a brief summary of this paper here
![[Pasted image 20240428171312.png]]
# Methodology
ğŸ’¡ Describe the methodology used in this paper
![[Pasted image 20240428171400.png]]
![[Pasted image 20240428171522.png]]
# Experiments
ğŸ’¡ List the experiments settings and results of this paper

# Related Papers
ğŸ’¡ Include any related papers that are relevant to this one

# Appendix
ğŸ’¡ Anything else thatâ€™s in this paper but not metioned before

---
# Resources
ğŸ’¡ Include some useful links for better understanding of this paper
- [DDIM åè½‰](https://blog.csdn.net/stevensmh/article/details/134286520)
- [Null-text Inversionï¼šåŸºæ–¼Null Prompt Finetuningçš„å½±åƒç·¨è¼¯æŠ€è¡“](https://zhuanlan.zhihu.com/p/622327208)
# Personal Notes
ğŸ’¡ Personal thoughts, reflections, or questions about this paper
---
title: Null-text Inversion for Editing Real Images using Guided Diffusion Models
time: 2211
author: Google Research; The Blavatnik School of Computer Science; Tel Aviv University
link: https://arxiv.org/pdf/2211.09794
accepted: CVPR23
tags:
  - Diffusion
  - Generation
  - Image
  - Text
  - Multimodal
  - Personalization
todo: true
scanned: false
read: false
summary: A method to inverse the DDIM process with CFG added, thus makes image editting possible and with good fidelity .
---
# Summary
💡 Write a brief summary of this paper here
![[Pasted image 20240428171312.png]]
# Methodology
💡 Describe the methodology used in this paper
![[Pasted image 20240428171400.png]]
![[Pasted image 20240428171522.png]]
# Experiments
💡 List the experiments settings and results of this paper

# Related Papers
💡 Include any related papers that are relevant to this one

# Appendix
💡 Anything else that’s in this paper but not metioned before

---
# Resources
💡 Include some useful links for better understanding of this paper
- [DDIM 反轉](https://blog.csdn.net/stevensmh/article/details/134286520)
- [Null-text Inversion：基於Null Prompt Finetuning的影像編輯技術](https://zhuanlan.zhihu.com/p/622327208)
# Personal Notes
💡 Personal thoughts, reflections, or questions about this paper
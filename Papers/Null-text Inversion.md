---
title: Null-text Inversion for Editing Real Images using Guided Diffusion Models
time: 2211
author: Google Research; The Blavatnik School of Computer Science; Tel Aviv University
link: https://arxiv.org/pdf/2211.09794
accepted: CVPR23
tags:
  - Diffusion
  - Generation
  - Image
  - Text
  - Multimodal
  - Personalization
todo: false
scanned: true
read: false
summary: A method to inverse the DDIM process with CFG added, thus makes image editting possible and with good fidelity.
---
# Summary
ğŸ’¡ Write a brief summary of this paper here
Applying [[Prompt-to-Prompt]] editing on real images by, first, inverting an input image using pivotal null-text optimization.
![[Pasted image 20240428171312.png]]
# Methodology
ğŸ’¡ Describe the methodology used in this paper
![[Pasted image 20250513173416.png]]
# Experiments
ğŸ’¡ List the experiments settings and results of this paper

# Related Papers
ğŸ’¡ Include any related papers that are relevant to this one
This is a follow-up work of [[Prompt-to-Prompt]]

# Appendix
ğŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ğŸ’¡ Include some useful links for better understanding of this paper
- [Null-text Inversionï¼šåŸºæ–¼Null Prompt Finetuningçš„å½±åƒç·¨è¼¯æŠ€è¡“](https://zhuanlan.zhihu.com/p/622327208)
- [DDIM Inversion - Hugging Face Diffusion Course](https://huggingface.co/learn/diffusion-course/unit4/2)
- [Null-text Inversion unofficial implementation](https://github.com/thepowerfuldeez/null-text-inversion/blob/main/null_text_inversion.ipynb)
# Personal Notes
ğŸ’¡ Personal thoughts, reflections, or questions about this paper
---
title: Null-text Inversion for Editing Real Images using Guided Diffusion Models
time: 2211
author: Google Research; The Blavatnik School of Computer Science; Tel Aviv University
link: https://arxiv.org/pdf/2211.09794
accepted: CVPR23
tags:
  - Diffusion
  - Generation
  - Image
  - Text
  - Multimodal
  - Personalization
todo: false
scanned: true
read: false
summary: A method to inverse the DDIM process with CFG added, thus makes image editting possible and with good fidelity.
---
# Summary
💡 Write a brief summary of this paper here
Applying [[Prompt-to-Prompt]] editing on real images by, first, inverting an input image using pivotal null-text optimization.
![[Pasted image 20240428171312.png]]
# Methodology
💡 Describe the methodology used in this paper
![[Pasted image 20250513173416.png]]
# Experiments
💡 List the experiments settings and results of this paper

# Related Papers
💡 Include any related papers that are relevant to this one
This is a follow-up work of [[Prompt-to-Prompt]]

# Appendix
💡 Anything else that’s in this paper but not mentioned before

---
# Resources
💡 Include some useful links for better understanding of this paper
- [Null-text Inversion：基於Null Prompt Finetuning的影像編輯技術](https://zhuanlan.zhihu.com/p/622327208)
- [DDIM Inversion - Hugging Face Diffusion Course](https://huggingface.co/learn/diffusion-course/unit4/2)
- [Null-text Inversion unofficial implementation](https://github.com/thepowerfuldeez/null-text-inversion/blob/main/null_text_inversion.ipynb)
# Personal Notes
💡 Personal thoughts, reflections, or questions about this paper
---
title: Pretraining is All You Need for Image-to-Image Translation
time: 2205
author: "The Hong Kong University of Science and Technology\r; Microsoft Research Asia"
link: https://arxiv.org/pdf/2205.12952
accepted: None
tags:
  - Diffusion
  - Image
  - ImageEditing
  - Personalization
todo: false
scanned: true
read: false
summary: They show that pretrained T2I models do better on image translation tasks
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
We propose to use pretraining to boost general image-to-image translation. 
Prior image-to-image translation methods usually need dedicated architectural design and train individual translation models from scratch, struggling for high-quality generation of complex scenes.
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20250112144403.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
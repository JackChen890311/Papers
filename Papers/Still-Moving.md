---
title: "Still-Moving: Customized Video Generation without Customized Video Data"
time: 2407
author: Google DeepMind; Tel Aviv University; Weizmann Institute of Science; Technion
link: https://arxiv.org/pdf/2407.08674
accepted: ACM24
tags:
  - Video
  - Generation
  - Personalization
  - Text
  - Multimodal
todo: false
scanned: true
read: false
summary: Adding adapters to T2I and T2V models for personalized video generation with no video data.
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
![[Pasted image 20250503114023.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20250503114059.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
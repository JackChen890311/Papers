---
title: Is Space-Time Attention All You Need for Video Understanding?
time: 2102
author: Facebook AI; Dartmouth College
link: https://arxiv.org/pdf/2102.05095
accepted: ICML21
tags:
  - Foundation
  - Video
  - Theory
todo: false
scanned: true
read: false
summary: A CNN free video classification network built on spatio & temporal attention, also compare the effect of different model structure.
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
- Conclude that "Devided spatio & temporal attention" leads to best performance
- Follows the [[ViT]] Structure
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20240529170341.png]]
![[Pasted image 20240529170354.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper
![[Pasted image 20240529170629.png]]
# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not metioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
- [Sora Review](https://github.com/lichao-sun/SoraReview)

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
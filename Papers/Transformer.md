---
title: Attention Is All You Need
time: 1706
author: Google Brain; Google Research; University of Toronto
link: https://arxiv.org/pdf/1706.03762.pdf
accepted: NIPS17
tags:
  - Text
  - Theory
  - Foundation
todo: false
scanned: true
read: false
summary: A structure that attends the data itself to gain a better understanding
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
The most famous self-attention & cross-attention (q and k, v are from different sources)
Also proposed the idea of positional embedding.
Solved the RNN parallelization problem.
![[Pasted image 20240205122634.png]]

# Methodology
ðŸ’¡ Describe the methodology used in this paper

![[Pasted image 20240205122647.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not metioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper
![[Pasted image 20231005183400.png]]
# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
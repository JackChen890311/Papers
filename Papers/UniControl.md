---
title: "UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild"
time: 2305
author: Salesforce AI Research; Northeastern University; Stanford Univeristy
link: https://arxiv.org/pdf/2305.11147.pdf
accepted: None
tags:
  - Diffusion
  - Generation
  - Image
  - Multimodal
  - Add-on
todo: false
scanned: true
read: false
summary: A unified ControlNet that can take different conditions at once.
---
# Summary
ðŸ’¡ Write a brief summary of this paper here
A unified version of [[ControlNet]] on [[Diffusion Models]].
Can take 8 different kinds of input images.
![[Pasted image 20240414101709.png]]
# Methodology
ðŸ’¡ Describe the methodology used in this paper
![[Pasted image 20240414101751.png]]
# Experiments
ðŸ’¡ List the experiments settings and results of this paper

# Related Papers
ðŸ’¡ Include any related papers that are relevant to this one

# Appendix
ðŸ’¡ Anything else thatâ€™s in this paper but not mentioned before

---
# Resources
ðŸ’¡ Include some useful links for better understanding of this paper

# Personal Notes
ðŸ’¡ Personal thoughts, reflections, or questions about this paper
# Introduction
# Related Work
## Diffusion Models
 - [[DDIM]]
 - [[DDPM]]
 - [[Classifier Guidance]]
 - [[unCLIP]]
 - [[Imagen]]
 - [[Latent Diffusion]]
## Personalized Generation
- [[Textual Inversion]]
- [[DreamBooth]]
- [[Break-A-Scene]]
- [[ConceptExpress]]
## Concept Learning
- [[ReVersion]]
- [[ADI]]
- [[Lego]]
## Concept Decomposition
- [[Conceptor]]
- [[InspirationTree]]
## Style-Content Decomposition
- [[ZipLoRA]]
- [[UnZipLoRA]]
- [[B-LoRA]]
# Preliminaries
## Latent Diffusion Models
- [[Latent Diffusion]]
## Textual Inversion
- [[Textual Inversion]]
## InspirationTree
- [[InspirationTree]]
## Attention Maps
- [[Prompt-to-Prompt]]
- [[DiffSeg]]
- [[DiffuMask]]
- [[ViCo]]
- [[Attend-and-Excite]]
- [[Break-A-Scene]]
- [[ConceptExpress]]
# Method
## Research Question
Can we utilize attention maps to decompose a foreground visual concept with better semantic meaning under a few-shot setting?
- [[Prompt-to-Prompt]]
- [[Break-A-Scene]]
- [[Attend-and-Excite]]
# Experiments
## Dataset
- [[InspirationTree]]
- [[Textual Inversion]]
- [[Custom-Diffusion]]
### Extended
- [[DreamBooth]]
## Evaluation Metric
- [[InspirationTree]]
- [[DETEX]]
- [[CLIP]]
- [[DINO]]
- [[SAM]]